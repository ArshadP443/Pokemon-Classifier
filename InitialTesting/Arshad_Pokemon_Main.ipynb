{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArshadP443/Pokemon-Classifier/blob/main/Arshad_Pokemon_Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqOXkW09kJZZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('pokemon-data.csv', delimiter=';') #Open the file\n",
        "df[\"Total\"] = df[\"HP\"] + df[\"Attack\"] + df[\"Defense\"] + df[\"Special Attack\"] + df[\"Special Defense\"] + df[\"Speed\"] # Add a new column for total / these columns are used for augmentation\n",
        "df[\"Tier\"] = df[\"Tier\"].fillna(\"none\") #Prevent future errors with null\n",
        "pokemon = df.drop(\"Name\", axis = 'columns') # Get rid of names (not useful)\n",
        "pokemon = pokemon.drop(\"Next Evolution(s)\", axis = 'columns') # Also not very useful\n",
        "pokemon = pokemon.drop_duplicates() # Remove duplicates\n",
        "print(len(pokemon[\"HP\"]))\n",
        "pokemon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sfcl4fgHVUB-"
      },
      "outputs": [],
      "source": [
        "column = list(pokemon.columns.values)\n",
        "for x in column[3:9]: # Augmentation - Add and subtract 1 to every column used in the augmentation listed above\n",
        "  for y in range(0, 816):\n",
        "    row = pokemon.iloc[y]\n",
        "    row[x] += 1\n",
        "    row[\"Total\"] += 1\n",
        "    pokemon = pokemon._append(row, ignore_index = True)\n",
        "    pokemon = pokemon.drop_duplicates()\n",
        "    row = pokemon.iloc[y]\n",
        "    row[x] -= 1\n",
        "    row[\"Total\"] -= 1\n",
        "    pokemon = pokemon._append(row, ignore_index = True)\n",
        "    pokemon = pokemon.drop_duplicates()\n",
        "pokemon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbgX6aJbX_OO"
      },
      "outputs": [],
      "source": [
        "pokemon.to_csv(\"Augmented_Pokemon_Final_.csv\") # Save new dataframe to new csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwaCKY9YQbf1"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder # Allows model to analyze strings\n",
        "Tiers = pokemon[\"Tier\"]\n",
        "pokemon = pokemon.drop(\"Tier\", axis = \"columns\")\n",
        "encode = OrdinalEncoder()\n",
        "encode.fit(pokemon)\n",
        "encode.transform(pokemon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qd6vQ0h_NXuU"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "enc = LabelEncoder()\n",
        "enc.fit(Tiers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjlVEkRR1wbv",
        "outputId": "b98bdbea-edef-415f-b140-af2611ab6186"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tier\n",
              "LC       3097\n",
              "PU       2586\n",
              "none     1129\n",
              "RU        747\n",
              "UU        690\n",
              "NU        660\n",
              "OU        632\n",
              "Uber      550\n",
              "UUBL      249\n",
              "RUBL      132\n",
              "NUBL      117\n",
              "PUBL       92\n",
              "Limbo      14\n",
              "AG         13\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "Tiers.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoTg7xtlm6TV",
        "outputId": "a9cc6811-d95f-4ac1-cd1d-ae77d0db9c09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 50.  19.  34. ...  62. 843. 238.]\n",
            " [ 43. 522.  62. ...  93. 773. 337.]\n",
            " [ 50.  19.  53. ...  52. 788. 306.]\n",
            " ...\n",
            " [ 48. 152.  46. ... 101. 152. 256.]\n",
            " [ 54.  32.  85. ...  21.  42. 237.]\n",
            " [173. 126.  39. ...  77. 286. 215.]]\n",
            "[10 11  5 ...  3  3 13]\n",
            "(2142, 10)\n",
            "(2142,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# normal process of splitting the data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    encode.transform(pokemon),\n",
        "    enc.transform(Tiers),\n",
        "    #random_state = 42,\n",
        "    test_size=0.2,\n",
        ")\n",
        "\n",
        "print(X_train)\n",
        "print(Y_train)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "#Dan DeGenaro (my instructor) taught me how to write this code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuuI1GBqow5N"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# initialize a scaler, just like a model\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# fit the scaler on the training data, and transform it as well while you're at it\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# ONLY transform the test data (NOT fit)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#Mr. DeGenaro also taught me how to do this as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkfwy37ImT77",
        "outputId": "c77fa1be-5341-49b4-e8ec-55201a5daaba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 6 1 ... 6 5 6] (2142,)\n",
            "[[  2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 611   0   0   0   0   0   0   0   0   0   0   0   8]\n",
            " [  0   0   3   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 114   0   0  30   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  24   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   1   0 119   1   0   0   0   6   0   1   0]\n",
            " [  0  11   0   0   0   2 513   0   1   0   0   0   0  10]\n",
            " [  0   0   0   0   0   0   0  19   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  11   0 128   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  22   0   0   0   0]\n",
            " [  0   0   0   0   0   0   6   0   0   0 128   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  48   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  95   0]\n",
            " [  0  14   0   0   0   0   2   0   0   0   0   0   0 212]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       0.96      0.99      0.97       619\n",
            "           2       1.00      1.00      1.00         3\n",
            "           3       0.99      0.79      0.88       144\n",
            "           4       1.00      1.00      1.00        24\n",
            "           5       0.98      0.93      0.96       128\n",
            "           6       0.91      0.96      0.93       537\n",
            "           7       1.00      1.00      1.00        19\n",
            "           8       0.99      0.92      0.96       139\n",
            "           9       1.00      1.00      1.00        22\n",
            "          10       0.96      0.96      0.96       134\n",
            "          11       1.00      1.00      1.00        48\n",
            "          12       0.99      1.00      0.99        95\n",
            "          13       0.92      0.93      0.93       228\n",
            "\n",
            "    accuracy                           0.95      2142\n",
            "   macro avg       0.98      0.96      0.97      2142\n",
            "weighted avg       0.95      0.95      0.95      2142\n",
            "\n",
            "['AG' 'LC' 'Limbo' 'NU' 'NUBL' 'OU' 'PU' 'PUBL' 'RU' 'RUBL' 'UU' 'UUBL'\n",
            " 'Uber' 'none']\n"
          ]
        }
      ],
      "source": [
        "#SVC results:\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "model = SVC(\n",
        "    #class_weight = {0:1, 1: 2, 2:1, 3:3},\n",
        "    kernel= \"rbf\",\n",
        "    C = 3,\n",
        "    degree = 1,\n",
        "    gamma = 'scale',\n",
        "    decision_function_shape = 'ovo',\n",
        "    probability = True,\n",
        ")\n",
        "model.fit(X_train, Y_train)\n",
        "Prediction = model.predict(X_test)\n",
        "print(Prediction, Prediction.shape)\n",
        "print(confusion_matrix(Y_test, Prediction))\n",
        "print(classification_report(Y_test, Prediction))\n",
        "print(enc.inverse_transform([0,1,2,3,4,5,6,7,8,9,10,11,12,13]))\n",
        "#He also helped me with this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMHQZmJgzFao"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "#SVC Training\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    \"class_weight\": [{0:1, 1:2, 2:1, 3:3}],\n",
        "    \"C\": [.35, .3],\n",
        "    \"kernel\": ['rbf'],\n",
        "    \"degree\": [1, 2, 3],\n",
        "    \"gamma\": [.1, 'scale', 'auto'],\n",
        "    \"decision_function_shape\": ['ovo'],\n",
        "    \"probability\": [True],\n",
        "}\n",
        "grid_search = GridSearchCV(SVC(),\n",
        "                           param_grid=param_grid)\n",
        "grid_search.fit(X_train, Y_train)\n",
        "print(grid_search.best_estimator_)\n",
        "\"\"\"\n",
        "# Code taken from https://www.geeksforgeeks.org/hyperparameter-tuning-using-gridsearchcv-and-kerasclassifier/?ref=oin_asr5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K3eYGxZt7Rsd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtgnfqcsrvYX"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "#DecisionTreeClassifier best results:\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "model = DecisionTreeClassifier(\n",
        "    class_weight = {0:1, 1:2, 2:.8, 3:2},\n",
        "    max_depth = 200,\n",
        "    max_features = 10000,\n",
        "    min_weight_fraction_leaf = .1,\n",
        "    min_impurity_decrease=0\n",
        ")\n",
        "model.fit(X_train, Y_train)\n",
        "Prediction = model.predict(X_test)\n",
        "print(Prediction, Prediction.shape)\n",
        "print(confusion_matrix(Y_test, Prediction))\n",
        "print(classification_report(Y_test, Prediction))\n",
        "print(enc.inverse_transform([0,1,2,3]))\n",
        "\"\"\"\n",
        "# Testing other models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJ36fq4jsnG7"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "#DesicionTreeClassifier Training\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    \"criterion\": [\"gini\",\"entropy\",\"log_loss\"],\n",
        "    'max_depth': [200,250,300],\n",
        "    \"min_weight_fraction_leaf\": [0.0, .1, .2],\n",
        "    \"max_features\": ['sqrt', 'log2', 100000, 100],\n",
        "    \"min_impurity_decrease\": [0, 1, 10, 50, 100],\n",
        "    \"class_weight\": [\"balanced\", {0:1, 1:2, 2:1, 3:2}, {0:1, 1:2, 2:.8, 3:2}, {0:1, 1:2, 2:.9, 3:4}]\n",
        "}\n",
        "grid_search = GridSearchCV(DecisionTreeClassifier(),\n",
        "                           param_grid=param_grid)\n",
        "grid_search.fit(X_train, Y_train)\n",
        "print(grid_search.best_estimator_)\n",
        "\"\"\"\n",
        "# Tested this model in similar ways"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ndf = pd.DataFrame(encode.transform(pokemon))\n",
        "ndf.style.background_gradient(cmap ='viridis').set_properties(**{'font-size': '20px'})\n",
        "# Heatmap to see what allowed for strong results (very varied/depends on the pokemon)"
      ],
      "metadata": {
        "id": "Fupnx6WLjCj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pokemon"
      ],
      "metadata": {
        "id": "ajx7zMu3rLF-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkMlHPcWX5lILpvDRlw8r/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
